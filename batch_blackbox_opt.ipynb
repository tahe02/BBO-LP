{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahe02/BBO-LP/blob/main/batch_blackbox_opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "AdSsjbvxs6Lm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5xohuVPFf68y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn import preprocessing\n",
        "from math import erfc\n",
        "from copy import deepcopy\n",
        "from scipy.stats import qmc\n",
        "\n",
        "RANDOM_STATE = 0\n",
        "\n",
        "np.random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Synthetic Functions"
      ],
      "metadata": {
        "id": "-hS4syqqdPBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class synthetic_function():\n",
        "    def __init__(self, d):\n",
        "        self.SobolSampler = qmc.Sobol(d=d, scramble=False)\n",
        "\n",
        "class Ackley(synthetic_function):\n",
        "    def __init__(self, d):\n",
        "        super().__init__(d)\n",
        "        self.dim = d\n",
        "        self.lower_bounds = [-32.768] * d \n",
        "        self.upper_bounds = [32.768] * d \n",
        "        self.candidates = self.SobolSampler.random_base2(m=14) \n",
        "\n",
        "    def f(self, x):\n",
        "        a = 20.0\n",
        "        b = 0.2\n",
        "        c = 2.0*np.pi\n",
        "        sum1 = np.sum(x**2, axis=1)\n",
        "        sum2 = np.sum(np.cos(c*x), axis=1)\n",
        "        res = -a * np.exp(-b*np.sqrt((1/self.dim) * sum1)) - np.exp((1/self.dim) * sum2) + a + np.exp(1)\n",
        "        return -res\n",
        "\n",
        "class Schwefel(synthetic_function):\n",
        "    def __init__(self, d):\n",
        "        super().__init__(d)\n",
        "        self.dim = d\n",
        "        self.lower_bounds = [-500.0] * d \n",
        "        self.upper_bounds = [500.0] * d\n",
        "        self.candidates = self.SobolSampler.random_base2(m=14)\n",
        "\n",
        "    def f(self, x):\n",
        "        res = 418.9829*self.dim - np.sum(x*np.sin(np.sqrt(np.abs(x))),axis=1)\n",
        "        return res\n",
        "\n",
        "class Rastrigin(synthetic_function):\n",
        "    def __init__(self, d):\n",
        "        super().__init__(d)\n",
        "        self.dim = d\n",
        "        self.lower_bounds = [-5.12] * d \n",
        "        self.upper_bounds = [5.12] * d\n",
        "        self.candidates = self.SobolSampler.random_base2(m=14)\n",
        "\n",
        "    def f(self, x):\n",
        "        tmp = x**2 - 10.0*np.cos(2*np.pi*x)\n",
        "        res = 10.0*self.dim - np.sum(tmp,axis=1)\n",
        "        return res"
      ],
      "metadata": {
        "id": "g7ZzR-1ijt-A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining functions"
      ],
      "metadata": {
        "id": "YFjYNdE1dvTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining acquisition functions\n",
        "\n",
        "def alpha_ei(mean_s, std_s, cur_best, epsilon=0.01):\n",
        "    meanY = mean_s\n",
        "    stdY = std_s\n",
        "    z = (meanY - cur_best - epsilon) / stdY\n",
        "    res = (meanY - cur_best - epsilon) * norm.cdf(z) + stdY * norm.pdf(z)\n",
        "    return res\n",
        "\n",
        "def alpha_ucb(mean_s, std_s, cur_best, beta=1.98):\n",
        "    res = mean_s+ beta*std_s\n",
        "    return res\n",
        "\n",
        "\n",
        "# Creating surrogate model classes\n",
        "\n",
        "class GPsur():\n",
        "  def __init__(self):\n",
        "      self.model = GaussianProcessRegressor(kernel=ConstantKernel()*Matern(), n_restarts_optimizer=10, random_state=RANDOM_STATE)\n",
        "  \n",
        "  def fit(self, x, y):\n",
        "    self.model.fit(x,y)\n",
        "\n",
        "  def predict(self, x, return_std=True):\n",
        "    return self.model.predict(x, return_std=return_std)\n",
        "\n",
        "class RFsur():\n",
        "  def __init__(self):\n",
        "      self.model = RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE)\n",
        "  \n",
        "  def fit(self, x, y):\n",
        "    self.model.fit(x,y)\n",
        "\n",
        "  def predict(self, x, return_std=True):\n",
        "    preds = []\n",
        "    for tree in self.model.estimators_:\n",
        "      preds.append(tree.predict(x))\n",
        "    means = np.mean(preds, axis=0)\n",
        "    stds = np.std(preds, axis=0)\n",
        "    if return_std:\n",
        "      return means, stds\n",
        "    return means\n",
        "\n",
        "\n",
        "# Estimating L-Lipschitz constant via maximum observed gradient\n",
        "\n",
        "\n",
        "def compute_norm(x1, x2):\n",
        "\n",
        "  norm = 0\n",
        "  try:\n",
        "    for i in range(len(x1)):\n",
        "      norm += (x1[i] - x2[i])**2\n",
        "  except TypeError:\n",
        "    norm = (x1 - x2)**2\n",
        "\n",
        "  return np.sqrt(norm)\n",
        "\n",
        "\n",
        "def estimate_L_UB(x_obs, y_obs, current_L, bsize, iteration):\n",
        "\n",
        "  rb = iteration*bsize\n",
        "  for i in range(len(x_obs)):\n",
        "    for j in range(rb, len(y_obs)):\n",
        "      rise = y_obs[i] - y_obs[j]\n",
        "\n",
        "      # Compute the distance between the two points\n",
        "      dist = compute_norm(x_obs[i], x_obs[j])\n",
        "\n",
        "      # Avoids div by 0 when points are the same\n",
        "      if dist != 0:\n",
        "        grad_norm = abs(rise/dist)\n",
        "      else:\n",
        "        grad_norm = -np.inf\n",
        "\n",
        "      current_L = max(current_L, grad_norm)\n",
        "  \n",
        "  return current_L\n",
        "\n",
        "# Acquisition transformation function\n",
        "def g_transform(z):\n",
        "  # if z >= 0:\n",
        "  #   return z\n",
        "  return np.log(1 + np.exp(z))\n",
        "\n",
        "\n",
        "# Defining penalising function\n",
        "\n",
        "\n",
        "def z_func(x_batch, sd, mu, L, M, pointspace):\n",
        "\n",
        "  norm = [compute_norm(x_batch, p) for p in pointspace]\n",
        "\n",
        "  z = [\n",
        "      ((L * d)-M+mu)/np.sqrt(2 * sd**2) for d in norm\n",
        "  ]\n",
        "  return z\n",
        "\n",
        "\n",
        "\n",
        "def phi(x_batch, sd, mu, L, M, pointspace):\n",
        "  z = z_func(x_batch, sd, mu, L, M, pointspace)\n",
        "  return [(erfc(-1*p))/2 for p in z]\n",
        "\n",
        "def create_space(dimpoints, dim=1):\n",
        "  \n",
        "  if dim == len(dimpoints):\n",
        "    return dimpoints[dim-1].reshape(-1,1)\n",
        "\n",
        "  lower = create_space(dimpoints, dim+1)\n",
        "  space = np.empty(0)\n",
        "  for p1 in lower:\n",
        "    for p2 in dimpoints[dim-1]:\n",
        "      space = np.append(space, np.insert(p1, 0, p2))\n",
        "\n",
        "  return space.reshape(-1, len(dimpoints)-dim+1)\n",
        "\n",
        "def BBO_LP(x_obs, y_obs, nb, m, model, function, dimension, resolution, pointspace):\n",
        "\n",
        "  maxes = []\n",
        "  batch_variance = []\n",
        "  Ls = []\n",
        "\n",
        "  # Set L to -inf when no estimate exists\n",
        "  L = -np.inf\n",
        "\n",
        "  for t in range(m):\n",
        "    # Define batch\n",
        "    batch = []\n",
        "\n",
        "    # Fit model to current dataset\n",
        "    model.fit(x_obs.reshape(-1, dimension), y_obs)\n",
        "\n",
        "    # Build acquisition function based on current fit   \n",
        "\n",
        "    pred_means, pred_stds = model.predict(pointspace, return_std=True)\n",
        "    alpha = alpha_ei(pred_means, pred_stds, np.max(y_obs))\n",
        "\n",
        "\n",
        "    # Apply g-stransformation to acquisition function\n",
        "    alpha_t_0 = [g_transform(p) for p in alpha]\n",
        "    \n",
        "    # Estimate L\n",
        "    L = estimate_L_UB(x_obs.reshape(-1, dimension), y_obs, L, nb, t)\n",
        "    Ls.append(L)\n",
        "\n",
        "    # Estimate M\n",
        "    M = max(y_obs)\n",
        "    maxes.append(M)\n",
        "\n",
        "    # Visualising Acquisition\n",
        "    # zscore = 1.96\n",
        "\n",
        "    # pred_uppers = pred_means+pred_stds*zscore # the 97.5th percentile of predictions\n",
        "    # pred_lowers = pred_means-pred_stds*zscore # the 2.5th percentile of predictions\n",
        "\n",
        "    # max_alpha_x = pointspace[np.argmax(alpha)]\n",
        "    # max_alpha_y = np.max(alpha)\n",
        "\n",
        "    # max_g0_x = pointspace[np.argmax(alpha_t_0)]\n",
        "    # max_g0_y = np.max(alpha_t_0)\n",
        "\n",
        "    # fig, ax1 = plt.subplots(figsize=(10,5))\n",
        "    # ax1.plot(pointspace.flatten(),function.f(pointspace), color=\"black\")\n",
        "    # ax1.fill_between(pointspace.flatten(), pred_uppers, pred_lowers,color=\"royalblue\", alpha=0.3)\n",
        "    # ax1.plot(pointspace.flatten(),pred_means, color=\"royalblue\")\n",
        "    # ax1.scatter(x_obs, y_obs)\n",
        "\n",
        "\n",
        "    # ax1.set_xlabel(\"x\")\n",
        "    # ax1.set_ylabel(\"f(x)\")\n",
        "\n",
        "    # ax2 = ax1.twinx()\n",
        "    # ax2.plot(pointspace.flatten(),alpha, color=\"green\")\n",
        "    # ax2.fill_between(pointspace.flatten(), 0, alpha, color=\"springgreen\",alpha=0.3, label=r\"$\\~{\\alpha}_{ei}(x)$\")\n",
        "    # ax2.scatter(max_alpha_x, max_alpha_y, s=200, marker=\"*\", color=\"yellow\", edgecolor=\"black\", zorder=10)\n",
        "    # ax2.set_ylim(0.0, np.max(alpha)*4.0)\n",
        "\n",
        "    # plt.title('Before Batch Selection {}'.format(t+1))\n",
        "    # plt.legend()\n",
        "    # plt.savefig(f'batch_{t+1}_acq_RF.png')\n",
        "    # plt.show()\n",
        "\n",
        "    alpha_t_j = deepcopy(alpha_t_0)\n",
        "\n",
        "    for j in range(nb):\n",
        "      # M step\n",
        "      batch_elem = pointspace[np.argmax(alpha_t_j)]      \n",
        "      batch.append(batch_elem)\n",
        "\n",
        "      # P step\n",
        "      phi_mult = [1 for p in pointspace.reshape(-1, dimension)]\n",
        " \n",
        "      sd = pred_stds[pointspace.tolist().index(batch_elem.tolist())]\n",
        "      mu = pred_means[pointspace.tolist().index(batch_elem.tolist())]\n",
        "\n",
        "      for k in range(j+1):\n",
        "        new_phi = phi(batch[k], sd, mu, L, M, pointspace)\n",
        "        phi_mult = [phi_mult[i] * new_phi[i] for i in range(len(phi_mult))]\n",
        "      \n",
        "      \n",
        "      alpha_t_j = [alpha_t_0[i] * phi_mult[i] for i in range(len(alpha_t_0))]\n",
        "\n",
        "      # Visualising Penalisation\n",
        "      # zscore = 1.96\n",
        "\n",
        "      # pred_uppers = pred_means+pred_stds*zscore # the 97.5th percentile of predictions\n",
        "      # pred_lowers = pred_means-pred_stds*zscore # the 2.5th percentile of predictions\n",
        "\n",
        "      # max_g_x = pointspace[np.argmax(alpha_t_j)]\n",
        "      # max_g_y = alpha_t_j[np.argmax(alpha_t_j)]\n",
        "      \n",
        "      # fig, ax1 = plt.subplots(figsize=(10,5))\n",
        "      # ax1.plot(pointspace.flatten(),function.f(pointspace), color=\"black\")\n",
        "      # ax1.fill_between(pointspace.flatten(), pred_uppers, pred_lowers,color=\"royalblue\", alpha=0.3)\n",
        "      # ax1.plot(pointspace.flatten(),pred_means, color=\"royalblue\")\n",
        "      # ax1.scatter(x_obs, y_obs)\n",
        "\n",
        "\n",
        "      # ax1.set_xlabel(\"x\")\n",
        "      # ax1.set_ylabel(\"f(x)\")\n",
        "\n",
        "      # ax2 = ax1.twinx()\n",
        "\n",
        "      # ax2.plot(pointspace.flatten(),alpha_t_j, color=\"orange\")\n",
        "      # ax2.fill_between(pointspace.flatten(), 0, alpha_t_j, color=\"orange\",alpha=0.3, label=r\"g($\\~{\\alpha}_{ei}(x)$)\")\n",
        "      # ax2.scatter(max_g_x, max_g_y, s=200, marker=\"*\", color=\"yellow\", edgecolor=\"black\", zorder=10)   \n",
        "\n",
        "      # ax2.plot(pointspace.flatten(), phi_mult, color='purple')\n",
        "\n",
        "      # ax2.set_ylim(0, np.max(alpha_t_j)*4)\n",
        "\n",
        "      # plt.title('transformed g after {} batch selections for batch {} ({}) with L = {}'.format(j+1, t+1, batch, L))\n",
        "\n",
        "      # plt.savefig(f'batch_{t+1}_selection{j+1}_RF.png')\n",
        "      # plt.show()\n",
        "    \n",
        "    # Evaluate the variance of points in the batch\n",
        "    batch_variance.append(np.var(batch))\n",
        "\n",
        "    # Evaluate the function at all batch point locations\n",
        "    for i in range(len(batch)):\n",
        "      x_obs = np.append(x_obs, batch[i])\n",
        "      y_obs = np.append(y_obs, function.f(batch[i].reshape(-1,dimension)))\n",
        " \n",
        "  model.fit(x_obs.reshape(-1, dimension), y_obs)\n",
        "  pred_means, pred_stds = model.predict(pointspace, return_std=True)\n",
        "\n",
        "  # Visualising Final Fit\n",
        "  # zscore = 1.96\n",
        "\n",
        "  # pred_uppers = pred_means+pred_stds*zscore # the 97.5th percentile of predictions\n",
        "  # pred_lowers = pred_means-pred_stds*zscore # the 2.5th percentile of predictions\n",
        "\n",
        "  # fig, ax1 = plt.subplots(figsize=(10,5))\n",
        "  # ax1.plot(pointspace.flatten(),function.f(pointspace), color=\"black\")\n",
        "  # ax1.fill_between(pointspace.flatten(), pred_uppers, pred_lowers,color=\"royalblue\", alpha=0.3)\n",
        "  # ax1.plot(pointspace.flatten(),pred_means, color=\"royalblue\")\n",
        "  # ax1.scatter(x_obs, y_obs)\n",
        "\n",
        "\n",
        "  # ax1.set_xlabel(\"x\")\n",
        "  # ax1.set_ylabel(\"f(x)\")\n",
        "\n",
        "  # plt.title('Final Fit')\n",
        "  # plt.legend()\n",
        "  # plt.savefig('final_RF.png')\n",
        "  # plt.show()\n",
        "\n",
        "  return x_obs.reshape(-1, dimension)[np.argmax(y_obs)]"
      ],
      "metadata": {
        "id": "KW4-patHaM0g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment parameters"
      ],
      "metadata": {
        "id": "2E5ahhExtGxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim = 1\n",
        "bounds = [[-10,10]]*dim\n",
        "func = Ackley(dim)\n",
        "bsize = 3\n",
        "iterations = 10\n",
        "resolution = 20"
      ],
      "metadata": {
        "id": "zaFWb8AF4f-h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create search space"
      ],
      "metadata": {
        "id": "0Rfe4XZZtNel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dimpoints = []\n",
        "\n",
        "for b in bounds:\n",
        "  dimpoints.append(np.linspace(b[0], b[1], (b[1] - b[0])*resolution))\n",
        "\n",
        "pointspace = create_space(dimpoints)"
      ],
      "metadata": {
        "id": "yvl8Rt87az9y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run experiment"
      ],
      "metadata": {
        "id": "FVMXs3rmtRlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating intitial points\n",
        "x_obs = np.random.uniform(low=-10, high=10, size=(bsize,dim))\n",
        "y_obs = func.f(x_obs.reshape(-1, dim))\n",
        "\n",
        "BBO_LP(\n",
        "    x_obs, y_obs, nb=bsize, m=iterations, model=RFsur(), function=func, dimension=dim, resolution=resolution, pointspace=pointspace\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2_XpLBm4GRL",
        "outputId": "b7154ea6-5a59-4e30-cf73-c0bb0628c603"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.02506266])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}